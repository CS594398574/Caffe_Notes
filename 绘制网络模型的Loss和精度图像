#-*-coding:utf-8-*-
import numpy as np
import matplotlib.pyplot as plt
import os
import caffe

#caffe_root = '/home/hjl/GoogleNet/'
caffe.set_device(0)
caffe.set_mode_gpu()
solver = caffe.SGDSolver('/home/hjl/GoogleNet/solver.prototxt')  #读取solver配置文件，该文件指向train_val网络文件，网络中包含了数据。因此不用显式的写数据输入

niter = 600                     #最大迭代次数，这个其实一般是指迭代了多少个batch.
test_interval = 100             #每训练迭代100次，就进行一次网络测试.
train_loss = np.zeros(niter)    #训练测试初始化为0.
test_acc = np.zeros(int(np.ceil(niter / test_interval)))  #测试精度初始化为0.

# the main solver loop
for it in range(niter):
    solver.step(1)  # SGD by Caffe
    # store the train loss
    train_loss[it] = solver.net.blobs['losses'].data    #提取caffe中bolobs结构里的losses数据，存放到train_loss中。
    solver.test_nets[0].forward(start='conv1/7x7_s2')   #表示从第一个卷积层开始前向传播，这样data层就不用传新的数据。

    if it % test_interval == 0:
        acc = solver.test_nets[0].blobs['accuracy'].data
        print 'Iteration', it, 'testing...', 'accuracy:', acc
        test_acc[it // test_interval] = acc   #将每次测试精度都保存的噢阿test_acc数组中。

print test_acc
_, ax1 = plt.subplots()
ax2 = ax1.twinx()
ax1.plot(np.arange(niter), train_loss)            #绘制训练loss
ax2.plot(test_interval * np.arange(len(test_acc)), test_acc, 'r')     #绘制测试acc
ax1.set_xlabel('iteration')
ax1.set_ylabel('train loss')
ax2.set_ylabel('test accuracy')
plt.show()
